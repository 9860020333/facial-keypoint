{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run this to update tensorflow or keras in case the model fails to load...\n",
    "# import sys\n",
    "# !{sys.executable} -m pip --upgrade tensorflow\n",
    "# !{sys.executable} -m pip --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model_path = r\"key_model\"\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return model\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_fit(image , keys, w, h):\n",
    "    color = (255,255,255)\n",
    "    isClosed = True\n",
    "    x = image\n",
    "    k = keys\n",
    "    #defining face shape:\n",
    "    p1 = [[int(k[4]),int(k[5])] , [int(k[12]),int(k[13])] , [int(k[14]),int(k[15])] , [int(k[6]),int(k[7])], [int(k[0]),int(k[1])]]\n",
    "    p2 = [[int(k[8]),int(k[9])] , [int(k[16]),int(k[17])] , [int(k[18]),int(k[19])] , [int(k[10]),int(k[11])], [int(k[2]),int(k[3])]]\n",
    "    p3 = [[int(k[20]),int(k[21])], [int(k[4]),int(k[5])] , [int(k[0]),int(k[1])], [int(k[6]),int(k[7])],[int(k[20]),int(k[21])], [int(k[8]),int(k[9])] , [int(k[2]),int(k[3])], [int(k[10]),int(k[11])]]\n",
    "#     p4 = [[int(k[20]),int(k[21])], [int(k[8]),int(k[9])] , [int(k[2]),int(k[3])], [int(k[10]),int(k[11])]]\n",
    "    p5 = [[int(k[10]),int(k[11])] , [int(k[20]),int(k[21])] , [int(k[22]),int(k[23])], [int(k[6]),int(k[7])], [int(k[24]),int(k[25])]]\n",
    "    p6 = [[int(k[22]),int(k[23])], [int(k[26]),int(k[27])] , [int(k[24]),int(k[25])], [int(k[28]),int(k[29])]]\n",
    "    feature=[p5,p3,p1,p2,p6]\n",
    "    for i in feature:\n",
    "        for j in i:\n",
    "            x=cv2.circle(np.reshape(np.array(x),(h,w,3)).astype('uint8'),(j[0],j[1]), radius = 2 ,color = (0,0,255),thickness = -1)\n",
    "        x = cv2.polylines(np.reshape(np.array(x),(h,w,3)).astype('uint8'), [np.array(i)], isClosed ,color,thickness = 0)\n",
    "    return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img , (500,500))\n",
    "    model = get_model()\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "        final_key = []\n",
    "        j=0\n",
    "        crop_image=gray[y:y+h , x:x+h]\n",
    "        dx= w/96\n",
    "        dy= h/96\n",
    "        resize_image = cv2.resize(crop_image, (96,96))\n",
    "        resize_image = np.array(resize_image).reshape(1,96,96)\n",
    "        c = np.array(model.predict(resize_image)).reshape(30)\n",
    "        for i in range(15):\n",
    "            all_x.append(math.ceil(c[j] * dx) + x)\n",
    "            all_y.append(math.ceil(c[j+1] * dy) + y)\n",
    "            j=j+2\n",
    "        for i in range(15):\n",
    "            final_key.append(int(all_x[i]))\n",
    "            final_key.append(int(all_y[i]))\n",
    "        final_key = np.array(final_key).reshape(30)\n",
    "        img = key_fit(img , final_key, int(np.array(gray).shape[1]), int(np.array(gray).shape[0]))\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera():\n",
    "    face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    model = get_model()\n",
    "    while True:\n",
    "        ret ,img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            #keypoint detecting:\n",
    "            all_x = []\n",
    "            all_y = []\n",
    "            final_key = []\n",
    "            j=0\n",
    "            crop_image=gray[y:y+h , x:x+h]\n",
    "            dx= w/96\n",
    "            dy= h/96\n",
    "            resize_image = cv2.resize(crop_image, (96,96))\n",
    "            resize_image = np.array(resize_image).reshape(1,96,96)\n",
    "            c = np.array(model.predict(resize_image)).reshape(30)\n",
    "            for i in range(15):\n",
    "                all_x.append(math.ceil(c[j] * dx) + x)\n",
    "                all_y.append(math.ceil(c[j+1] * dy) + y)\n",
    "                j=j+2\n",
    "            for i in range(15):\n",
    "                final_key.append(int(all_x[i]))\n",
    "                final_key.append(int(all_y[i]))\n",
    "            final_key = np.array(final_key).reshape(30)\n",
    "            img = key_fit(img , final_key, int(width), int(height))\n",
    "\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video(path):\n",
    "    print(\"loading the algorithm....\")\n",
    "    face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    model = get_model()\n",
    "    print(\"PROCESSING THE VIDEO...please wait\")\n",
    "    while(cap.isOpened()):\n",
    "        ret ,img = cap.read()\n",
    "#         img = cv2.resize(img, (700,400))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            #keypoint detecting:\n",
    "            all_x = []\n",
    "            all_y = []\n",
    "            final_key = []\n",
    "            j=0\n",
    "            crop_image=gray[y:y+h , x:x+h]\n",
    "            dx= w/96\n",
    "            dy= h/96\n",
    "            resize_image = cv2.resize(crop_image, (96,96))\n",
    "            resize_image = np.array(resize_image).reshape(1,96,96)\n",
    "            c = np.array(model.predict(resize_image)).reshape(30)\n",
    "            for i in range(15):\n",
    "                all_x.append(math.ceil(c[j] * dx) + x)\n",
    "                all_y.append(math.ceil(c[j+1] * dy) + y)\n",
    "                j=j+2\n",
    "            for i in range(15):\n",
    "                final_key.append(int(all_x[i]))\n",
    "                final_key.append(int(all_y[i]))\n",
    "            final_key = np.array(final_key).reshape(30)\n",
    "            img = key_fit(img , final_key, int(width), int(height))   \n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1) realtime keypoint tracking \\n 2) image keypoint tracking \\n 3) video keypoint tracking\")\n",
    "choice = input()\n",
    "if(choice == '1'):\n",
    "    camera()\n",
    "elif(choice == '2'):\n",
    "    print(\"enter the image path:\")\n",
    "    path = input()\n",
    "    photo(path)\n",
    "else:\n",
    "    \n",
    "\n",
    "    print(\"enter the video path:\")\n",
    "    path = input()\n",
    "    video(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try image_path = 5.jpeg or  9.jpg\n",
    "#try video_path = original.MOV\n",
    "# press escape to get out of the live webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit1db4d713191d4539ad9e32516778e193"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
